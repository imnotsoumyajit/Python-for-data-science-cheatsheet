{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bf93127-c27d-443d-a39a-6f017455d464",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3[extra] in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: importlib-metadata~=4.13 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (4.13.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (1.5.3)\n",
      "Requirement already satisfied: gym==0.21 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (0.21.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (2.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (1.23.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (3.5.3)\n",
      "Requirement already satisfied: torch>=1.11 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (2.0.0)\n",
      "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (0.4.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (9.2.0)\n",
      "Requirement already satisfied: rich in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (13.3.3)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (4.7.0.72)\n",
      "Requirement already satisfied: tqdm in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (4.65.0)\n",
      "Requirement already satisfied: ale-py==0.7.4 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (0.7.4)\n",
      "Requirement already satisfied: psutil in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (5.9.4)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3[extra]) (2.12.1)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ale-py==0.7.4->stable-baselines3[extra]) (5.12.0)\n",
      "Requirement already satisfied: click in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (8.1.3)\n",
      "Requirement already satisfied: requests in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.28.2)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (0.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from importlib-metadata~=4.13->stable-baselines3[extra]) (3.15.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.2.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.17.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (65.5.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.4.3)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (4.22.1)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.40.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.53.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11->stable-baselines3[extra]) (3.10.7)\n",
      "Requirement already satisfied: sympy in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11->stable-baselines3[extra]) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11->stable-baselines3[extra]) (3.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11->stable-baselines3[extra]) (4.5.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11->stable-baselines3[extra]) (3.1.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (4.37.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2023.3)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->stable-baselines3[extra]) (2.14.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->stable-baselines3[extra]) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->stable-baselines3[extra]) (0.4.6)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.2)\n",
      "Requirement already satisfied: libtorrent in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from AutoROM.accept-rom-license->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.0.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch>=1.11->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e443ebd-62ec-416b-9ec5-4b17e6564be1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3) (1.23.2)\n",
      "Requirement already satisfied: torch>=1.11 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3) (2.0.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3) (3.5.3)\n",
      "Requirement already satisfied: importlib-metadata~=4.13 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3) (4.13.0)\n",
      "Requirement already satisfied: gym==0.21 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3) (0.21.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3) (2.2.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stable-baselines3) (1.5.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from importlib-metadata~=4.13->stable-baselines3) (3.15.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11->stable-baselines3) (3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11->stable-baselines3) (3.1.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11->stable-baselines3) (3.10.7)\n",
      "Requirement already satisfied: sympy in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11->stable-baselines3) (1.11.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11->stable-baselines3) (4.5.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->stable-baselines3) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->stable-baselines3) (4.37.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->stable-baselines3) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->stable-baselines3) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->stable-baselines3) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->stable-baselines3) (9.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->stable-baselines3) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=1.11->stable-baselines3) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch>=1.11->stable-baselines3) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install stable-baselines3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86557a9d-1763-4d46-b608-fe48b445eba5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyglet==1.5.27\n",
      "  Using cached pyglet-1.5.27-py3-none-any.whl (1.1 MB)\n",
      "Installing collected packages: pyglet\n",
      "Successfully installed pyglet-1.5.27\n"
     ]
    }
   ],
   "source": [
    "!pip install pyglet==1.5.27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf2cf0db-dcfd-4b92-ad9f-7993e9d9b4c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyglet in c:\\users\\soumyajit mondal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.5.27)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyglet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3002f58-5c85-49c7-9a2b-5018d78ea658",
   "metadata": {},
   "source": [
    "ref :https://gymnasium.farama.org/environments , \n",
    "https://gymnasium.farama.org/environments/atari/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6680b233-0ee4-4807-b5f5-5463726c8d61",
   "metadata": {},
   "source": [
    "## import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c74a80a-9fc6-4202-819d-c110b082e307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import stable_baselines3\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183efb93-0ab5-4480-8045-25492dfe003a",
   "metadata": {},
   "source": [
    "## load the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d814a5d5-10a4-428d-8bfe-57230c535b64",
   "metadata": {},
   "source": [
    "https://gymnasium.farama.org/environments/classic_control/cart_pole/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1522cc72-6a3a-45bf-b46a-2c8d1342aa5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env_name='CartPole-v1'\n",
    "env=gym.make(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7d678c4-b799-4567-86f3-b2c112cca4f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:13.0\n",
      "Episode:2 Score:55.0\n",
      "Episode:3 Score:14.0\n",
      "Episode:4 Score:27.0\n",
      "Episode:5 Score:45.0\n"
     ]
    }
   ],
   "source": [
    "# we loop 5 times\n",
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9979221f-f061-44f8-814a-f761741d57b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfe14a9-5a3d-4965-9b63-80f3510abd7e",
   "metadata": {},
   "source": [
    "### Understand the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e47880e-7026-4b98-8e83-3ce6d7fdb679",
   "metadata": {},
   "source": [
    "ref :https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1148ad34-7bad-4085-a1ea-e1ca1760322b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c091354d-d4d0-4742-854c-a1e69f8529cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "# get our initial set of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29559f00-d348-4e35-b156-71e2cf19faf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ac1619-5d02-4801-86bf-27c22d6f5a05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2a2edb-0d0e-43a7-a92e-4b1f92365cef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env.action_space.sample()\n",
    "# either 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b26ed30-3dfc-4014-84bb-8a05edc2f695",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9052ce8-7198-43e2-9a9e-2867f6b0db7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6183e3ea-45fb-4e39-bf20-b8481637e77b",
   "metadata": {},
   "source": [
    "## train a reinforcement learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d450b0a-b08d-4092-89d6-350f7b4dba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# where we save our tensorboard log\n",
    "log_path=os.path.join('Training','Logs')\n",
    "# log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a78050bc-1bd5-4452-816e-5863a3f6f7ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "env=gym.make(env_name)\n",
    "env=DummyVecEnv([lambda:env])\n",
    "model=PPO('MlpPolicy',env,verbose=1,tensorboard_log=log_path)\n",
    "# mlp : multi layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fb99a7b-f45d-4f74-afe5-b4689760dc89",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\PPO_4\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 955  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 2    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 649         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008617599 |\n",
      "|    clip_fraction        | 0.0976      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | -0.00115    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.05        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 52.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 589         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010118492 |\n",
      "|    clip_fraction        | 0.0657      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.666      |\n",
      "|    explained_variance   | 0.0754      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    value_loss           | 36.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 559         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007667931 |\n",
      "|    clip_fraction        | 0.0778      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.635      |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    value_loss           | 54          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 549          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080688065 |\n",
      "|    clip_fraction        | 0.0986       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.611       |\n",
      "|    explained_variance   | 0.364        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 27           |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0206      |\n",
      "|    value_loss           | 61.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 539         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012731489 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.587      |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    value_loss           | 59.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 531         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009017601 |\n",
      "|    clip_fraction        | 0.0794      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.59       |\n",
      "|    explained_variance   | 0.508       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 52.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 529         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007877253 |\n",
      "|    clip_fraction        | 0.0767      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.568      |\n",
      "|    explained_variance   | 0.589       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.61        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 55.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 528         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006686561 |\n",
      "|    clip_fraction        | 0.0733      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.58       |\n",
      "|    explained_variance   | 0.816       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.55        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 29          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 523         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010586141 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.555      |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 49.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x229537374c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86ebd7d-95fa-41ae-bd05-86c4d5678caf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc3ff5f4-8b9d-46e8-acc5-f2d91dfd134f",
   "metadata": {},
   "source": [
    "## save and reload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0f768df-d98e-49b8-8534-51dd6f30aaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_Path=os.path.join('Training','Saved Models','PPO_MODEL_Cartpole')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ee77408-2dfb-442b-89f8-cc2ea744f9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(PPO_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9ffec13-99a9-4f78-a77d-16cf824a0405",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training\\\\Saved Models\\\\PPO_MODEL_Cartpole'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PPO_Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e73e4624-2347-4e0e-866c-091ce346e53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ba9f085-eef5-4621-bc37-92e2fbaf22c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\PPO_5\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 889  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 2    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x229537374c0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354b8687-1d37-45a5-8efa-f975510cd366",
   "metadata": {},
   "source": [
    "Loading model ref : https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a8377b3-f877-4bb3-8216-08d9bd05376e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading our model\n",
    "model = PPO.load(PPO_Path,env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8126ed1f-7383-4c89-ae48-4b558c7ae15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=PPO.load(os.path.join('Training','Saved Models','PPO_MODEL_Cartpole.zip'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bde0436-4016-4eaa-99a1-ea10d6b6a173",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b2d106-453c-46bd-8cfb-c8bb37aa4a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Soumyajit Mondal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "evaluate_policy(model,env,n_eval_episodes=10,render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b076e1d-27e8-4353-9800-906e2780295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b22cd28-eaa7-471b-aea4-b820c934de5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c20926c-ad22-4bf7-a649-11670c9b9859",
   "metadata": {
    "tags": []
   },
   "source": [
    "## test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fd6c55c-ca7e-4e25-962d-192dad27d60f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "action,_=model.predict(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57e167a6-7d8c-45ca-9b23-3bdbeabbb29f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfd6721-0ef7-4f34-8a07-02d5e04bf185",
   "metadata": {},
   "source": [
    "meaning of the observations : https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebe0be70-3d5c-4085-8cc3-502cd8ca23e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00551797, -0.02888318,  0.04987972,  0.04531725]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs #observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c36c79ab-9541-4472-b76a-279a40fd0587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:[500.]\n",
      "Episode:2 Score:[363.]\n",
      "Episode:3 Score:[500.]\n",
      "Episode:4 Score:[500.]\n",
      "Episode:5 Score:[500.]\n"
     ]
    }
   ],
   "source": [
    "# we loop 5 times\n",
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    obs = env.reset() #changeed name (state->obs)\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action,_ = model.predict(obs) # now we use our own model and '_' to unpack as we get 2 return values \n",
    "        obs, reward, done, info = env.step(action) ##changeed name (n_state->obs)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ab853e9-3718-414a-938b-85b07e1b8756",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31a30261-5ead-41cb-ba87-9eee41aeedec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0336252 , -0.04815029,  0.00838828, -0.04133819]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31444255-d7d8-44e9-b7ea-004fd6401158",
   "metadata": {},
   "source": [
    "Our rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ac042d5-3818-4ecb-b4c1-f64a972b819d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.04463546, -0.21049654, -0.01898251,  0.24235038]],\n",
       "       dtype=float32),\n",
       " array([1.], dtype=float32),\n",
       " array([False]),\n",
       " [{}])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c45fd6-c362-435a-93e9-155ac77b23d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f409e655-6d72-4e44-9a13-26247eb8b34c",
   "metadata": {},
   "source": [
    "## view logs on tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ac548d5-710a-4f54-85a2-fc8a23efe5aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training\\\\Logs'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a954472-b85e-4f10-98af-017782d75dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_log_path=os.path.join(log_path,'PPO_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31784ccb-24a5-4700-a1ca-3a0cbf0e1d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir=training_log_path\n",
    "# tensorboard --logdir='Training/Logs/PPO3'\n",
    "# recc- do this shit in another terminal , not here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f304a450-cae4-43b7-be39-c2b7f910dc99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8748e24f-0d09-4edd-88fa-0e2f46f2121c",
   "metadata": {},
   "source": [
    "## adding a callback to their training stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8369d1c-6a7e-494b-8e20-ecc475d131a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback,StopTrainingOnRewardThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76d86a8e-059e-43b1-b6cf-ab8cb72b8ad5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_path=os.path.join('Training','Saved Models') #we save our best model here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ac75b14-43ad-4f00-9eb7-703ccf05cf0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop_callback=StopTrainingOnRewardThreshold(reward_threshold=200,verbose=1)\n",
    "eval_callback=EvalCallback(env,\n",
    "                          callback_on_new_best=stop_callback,\n",
    "                          eval_freq=10000,\n",
    "                          best_model_save_path=save_path,\n",
    "                          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3691ca93-6444-4888-aa3a-314fafb5a39d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "model = PPO('MlpPolicy',env,verbose=1,tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41ea0aa3-1ec9-4f82-a9c7-7fef17e32fa5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\PPO_6\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 902  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 2    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 632         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009413833 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.685      |\n",
      "|    explained_variance   | -0.00105    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.53        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    value_loss           | 50.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 572         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009092096 |\n",
      "|    clip_fraction        | 0.0526      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.664      |\n",
      "|    explained_variance   | 0.0987      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 36.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 542          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071068304 |\n",
      "|    clip_fraction        | 0.0907       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.629       |\n",
      "|    explained_variance   | 0.243        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 19.1         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0178      |\n",
      "|    value_loss           | 54.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Soumyajit Mondal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=10000, episode_reward=269.00 +/- 122.02\n",
      "Episode length: 269.00 +/- 122.02\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 269          |\n",
      "|    mean_reward          | 269          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073200697 |\n",
      "|    clip_fraction        | 0.0607       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.609       |\n",
      "|    explained_variance   | 0.294        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 25.3         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0161      |\n",
      "|    value_loss           | 61.9         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "Stopping training because the mean reward 269.00  is above the threshold 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x22960c34f40>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=20000,callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e75543-0c3e-49fe-9ca1-da6b74f166dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc8d7971-8130-42f6-8c34-cb19ceb84262",
   "metadata": {},
   "source": [
    "## changing policies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31280b3f-ce12-4614-bf18-2969fd5714e0",
   "metadata": {},
   "source": [
    "ref : https://stable-baselines3.readthedocs.io/en/master/guide/custom_policy.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9bb5484-2de8-4223-8a8d-349b51df4e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new Neural Network Architecture \n",
    "net_arch=[dict(pi=[128,128,128,128],vf=[128,128,128,128])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9e5ddbc-58a6-49f6-a8fe-2814986236ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Soumyajit Mondal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\common\\policies.py:458: UserWarning: As shared layers in the mlp_extractor are deprecated and will be removed in SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model=PPO('MlpPolicy',env,verbose=1,tensorboard_log=log_path,policy_kwargs={'net_arch':net_arch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39a86783-f224-46f3-823c-73c5593968a2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_callback' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mlearn(total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20000\u001b[39m,callback\u001b[38;5;241m=\u001b[39m\u001b[43meval_callback\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'eval_callback' is not defined"
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=20000,callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a090c7a9-3a9d-4e8b-b112-a125d124716b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27515995-a8a8-4060-bd39-3308bea2b54a",
   "metadata": {},
   "source": [
    "## using alternate algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9dd6cfc-941e-4b76-aa83-b2b00b7d9e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f512fed9-97bc-4c19-803a-98df4b4b7912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m=\u001b[39m\u001b[43mDQN\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMlpPolicy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtensorboard_log\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnet_arch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mnet_arch\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\dqn\\dqn.py:137\u001b[0m, in \u001b[0;36mDQN.__init__\u001b[1;34m(self, policy, env, learning_rate, buffer_size, learning_starts, batch_size, tau, gamma, train_freq, gradient_steps, replay_buffer_class, replay_buffer_kwargs, optimize_memory_usage, target_update_interval, exploration_fraction, exploration_initial_eps, exploration_final_eps, max_grad_norm, tensorboard_log, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_net, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_net_target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _init_setup_model:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\dqn\\dqn.py:140\u001b[0m, in \u001b[0;36mDQN._setup_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_setup_model\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_aliases()\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;66;03m# Copy running stats, see GH issue #996\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:215\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm._setup_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_buffer_class(\n\u001b[0;32m    206\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_size,\n\u001b[0;32m    207\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_buffer_kwargs,\n\u001b[0;32m    213\u001b[0m     )\n\u001b[1;32m--> 215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_class(  \u001b[38;5;66;03m# pytype:disable=not-instantiable\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space,\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space,\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_schedule,\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_kwargs,  \u001b[38;5;66;03m# pytype:disable=not-instantiable\u001b[39;00m\n\u001b[0;32m    220\u001b[0m )\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    223\u001b[0m \u001b[38;5;66;03m# Convert train freq parameter to TrainFreq object\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\dqn\\policies.py:148\u001b[0m, in \u001b[0;36mDQNPolicy.__init__\u001b[1;34m(self, observation_space, action_space, lr_schedule, net_arch, activation_fn, features_extractor_class, features_extractor_kwargs, normalize_images, optimizer_class, optimizer_kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet_args \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobservation_space\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space,\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction_space\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalize_images\u001b[39m\u001b[38;5;124m\"\u001b[39m: normalize_images,\n\u001b[0;32m    145\u001b[0m }\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_net, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_net_target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr_schedule\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\dqn\\policies.py:160\u001b[0m, in \u001b[0;36mDQNPolicy._build\u001b[1;34m(self, lr_schedule)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_build\u001b[39m(\u001b[38;5;28mself\u001b[39m, lr_schedule: Schedule) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    151\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;124;03m    Create the network and the optimizer.\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m        lr_schedule(1) is the initial learning rate\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_net \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_q_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_net_target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_q_net()\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_net_target\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_net\u001b[38;5;241m.\u001b[39mstate_dict())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\dqn\\policies.py:171\u001b[0m, in \u001b[0;36mDQNPolicy.make_q_net\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_q_net\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m QNetwork:\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;66;03m# Make sure we always have separate networks for features extractors etc\u001b[39;00m\n\u001b[0;32m    170\u001b[0m     net_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_features_extractor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet_args, features_extractor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m QNetwork(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnet_args)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\dqn\\policies.py:55\u001b[0m, in \u001b[0;36mQNetwork.__init__\u001b[1;34m(self, observation_space, action_space, features_extractor, features_dim, net_arch, activation_fn, normalize_images)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures_dim \u001b[38;5;241m=\u001b[39m features_dim\n\u001b[0;32m     54\u001b[0m action_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mn  \u001b[38;5;66;03m# number of actions\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m q_net \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_mlp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet_arch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_net \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\u001b[38;5;241m*\u001b[39mq_net)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\common\\torch_layers.py:133\u001b[0m, in \u001b[0;36mcreate_mlp\u001b[1;34m(input_dim, output_dim, net_arch, activation_fn, squash_output, with_bias)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03mCreate a multi layer perceptron (MLP), which is\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03ma collection of fully-connected layers each followed by an activation function.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m:return:\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(net_arch) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 133\u001b[0m     modules \u001b[38;5;241m=\u001b[39m [\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet_arch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_bias\u001b[49m\u001b[43m)\u001b[49m, activation_fn()]\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    135\u001b[0m     modules \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:96\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[1;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_features \u001b[38;5;241m=\u001b[39m in_features\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_features \u001b[38;5;241m=\u001b[39m out_features\n\u001b[1;32m---> 96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty((out_features, in_features), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs))\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty(out_features, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs))\n",
      "\u001b[1;31mTypeError\u001b[0m: empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "model=DQN('MlpPolicy',env,verbose=1,tensorboard_log=log_path,policy_kwargs={'net_arch':net_arch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009d1ce5-0cc7-4721-8224-fc56fd572c95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0306f3-dd6e-4b93-b70f-09e699f8dfd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe28fec8-25e4-46bf-8f74-edb9a99207f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
